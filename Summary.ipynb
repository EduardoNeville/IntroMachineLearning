{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Summary: AdaBoost\n",
    "Used in non linearly separable data\n",
    "Iteratively building a weighted sum of weak classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# good to import few packages\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def display_digit(image, label, training_or_inferred = \"training\"):\n",
    "    \"\"\"\n",
    "    graphically display a 784x1 vector, representing a digit, and show the corresponding label\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    fig = plt.imshow(image.reshape(28,28))\n",
    "    fig.set_cmap('gray_r')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    if training_or_inferred == \"training\":\n",
    "        title_str = \"GT label: \"\n",
    "    else:\n",
    "        title_str = \"Inferred label: \"\n",
    "    plt.title(title_str  + str(int(label)))\n",
    "\n",
    "def display_vector(vector):\n",
    "    \"\"\"\n",
    "    graphically display a 784x1 vector, representing a digit, without showing the label\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    fig = plt.imshow(vector.reshape(28,28))\n",
    "    fig.set_cmap('gray_r')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size\n",
    "\n",
    "train_data = np.loadtxt(\"../mnist_train.csv\", delimiter=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AdaBoost Algorithm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def fit(self,nit=10):\n",
    "    # Initialize weights and list of classifiers\n",
    "    self.weakCls = []\n",
    "    bestAcc = 0.0\n",
    "    self.datCoeffs = np.ones(self.ns,dtype=np.float)/self.ns\n",
    "    # Find nit weak classifiers and update weights each time.\n",
    "    for m in range(nit):\n",
    "        weakC=self.getWeakC()\n",
    "        self.weakCls.append(weakC)\n",
    "        weakC.alpha=self.updateWeights(weakC)\n",
    "\n",
    "\n",
    "def updateWeights(self,weakC):\n",
    "    # Compute alpha\n",
    "    err,_ = self.weakClassError(weakC)\n",
    "    alpha = np.log(1.0/max(1e-10,err)-1.0)\n",
    "    # Compute numbers of misclassified samples.\n",
    "    nerrs = np.logical_not(weakC.predict(self.xs)==self.ys) # Update and normalize weights.\n",
    "    self.datCoeffs *= np.exp(alpha*nerrs)\n",
    "    self.datCoeffs /= sum (self.datCoeffs)\n",
    "    return alpha"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adaboost scheme\n",
    "Note: The weakClassifiers don't have to be linear\n",
    "Steps to be taken:\n",
    "1. We itterate on the classifiers and then append the new classifier onto the set of classifiers to improve sum of classifiers\n",
    "2. Updating the weights:\n",
    "        2.1 We check for the error in the classification after the use of the last classifier\n",
    "        2.2 Computing alpha as a minimization of the error we just recieved and use as the new weight\n",
    "        2.3 Find all the misclassified samples and update their weights and normalize them"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def fit(self,nit=10):\n",
    "    # Initialize weights and list of classifiers\n",
    "    self.weakCls = []\n",
    "    bestAcc = 0.0\n",
    "    self.datCoeffs = np.ones(self.ns,dtype=np.float)/self.ns\n",
    "    # Find nit weak classifiers and update weights each time.\n",
    "    for m in range(nit):\n",
    "       weakC=self.getWeakC()\n",
    "       self.weakCls.append(weakC)\n",
    "       weakC.alpha=self.updateWeights(weakC)\n",
    "\n",
    "def updateWeights(self,weakC):\n",
    "    # Compute alpha\n",
    "    err,_ = self.weakClassError(weakC)\n",
    "    alpha = np.log(1.0/max(1e-10,err)-1.0)\n",
    "    # Compute numbers of misclassified samples.\n",
    "    nerrs = np.logical_not(weakC.predict(self.xs)==self.ys) # Update and normalize weights.\n",
    "    self.datCoeffs *= np.exp(alpha*nerrs)\n",
    "    self.datCoeffs /= sum (self.datCoeffs)\n",
    "    return alpha"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVMs\n",
    "Similar to how AdaBoost works it utilises weaker weights to improve on the current values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Linear SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}