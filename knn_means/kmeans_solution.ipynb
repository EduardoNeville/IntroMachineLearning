{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Session 4: K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will work on K-means clustering. You will be asked to cluster the MNIST dataset using the k-means algorithm. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from json import loads\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# set matplotlib to display all plots inline with the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions we use to load the data and visualize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_digit(image, label, training_or_inferred = \"training\"):\n",
    "    \"\"\" \n",
    "    graphically display a 784x1 vector, representing a digit, and show the corresponding label\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    plt.figure()\n",
    "    fig = plt.imshow(image.reshape(28,28))\n",
    "    fig.set_cmap('gray_r')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "    if training_or_inferred == \"training\":\n",
    "        title_str = \"GT label: \"\n",
    "    else:\n",
    "        title_str = \"Inferred label: \"\n",
    "    plt.title(title_str  + str(int(label)))\n",
    "    \n",
    "def display_vector(vector):\n",
    "    \"\"\" \n",
    "    graphically display a 784x1 vector, representing a digit, without showing the label\n",
    "    \n",
    "    \"\"\"\n",
    " \n",
    "    plt.figure()\n",
    "    fig = plt.imshow(vector.reshape(28,28))\n",
    "    fig.set_cmap('gray_r')\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Dataset\n",
    "\n",
    "### Load and Visualize dataset\n",
    "\n",
    "The MNIST database contains a total of 70,000 handwritten digits with 10 different classes, from 0 to 9. 60,000 examples are taken as training dataset and the remaining 10,000 as test set. The digits have been size-normalized and centered in a fixed-size image. \n",
    "\n",
    "First download MNIST from: https://www.python-course.eu/data/mnist/mnist_train.csv\n",
    "and put this csv file in the same folder as your jupyter notebook file. (You may have already done this in a previous exercise, it is fine to reuse the same csv file)\n",
    "\n",
    "Each image is of size 784 with integers in the range $[0, 255]$, and the images can be reshaped to $28 \\times 28$. The value of the pixels indicate the brightness of a pixel, that is, the higher number the brighter the pixel.\n",
    "\n",
    "To make sure everything went fine, we will first load the dataset and visualize some samples from it. It might take a while to load it into memory! We will then subsample the dataset. The MNIST database is huge, and our algorithm will take very long if we want to use all the data. Therefore we will only use the first 1200 samples as our training dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "downloaded.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/7w/90j0w4m514d4j00s68mtmt_r0000gn/T/ipykernel_16420/2186482497.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mimage_pixels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimage_size\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mimage_size\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mtrain_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloadtxt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"downloaded.csv\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdelimiter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\",\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mloadtxt\u001B[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001B[0m\n\u001B[1;32m   1065\u001B[0m             \u001B[0mfname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos_fspath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_string_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m             \u001B[0mfh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_datasource\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rt'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m             \u001B[0mfencoding\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfh\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'encoding'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'latin1'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m             \u001B[0mfh\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfh\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/lib/_datasource.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(path, mode, destpath, encoding, newline)\u001B[0m\n\u001B[1;32m    191\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m     \u001B[0mds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDataSource\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdestpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 193\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mencoding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnewline\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mnewline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    194\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    195\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.9/site-packages/numpy/lib/_datasource.py\u001B[0m in \u001B[0;36mopen\u001B[0;34m(self, path, mode, encoding, newline)\u001B[0m\n\u001B[1;32m    531\u001B[0m                                       encoding=encoding, newline=newline)\n\u001B[1;32m    532\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 533\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mIOError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"%s not found.\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    534\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    535\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOSError\u001B[0m: downloaded.csv not found."
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "image_size = 28 # width and length\n",
    "no_of_different_labels = 10 #  i.e. 0, 1, 2, 3, ..., 9\n",
    "image_pixels = image_size * image_size\n",
    "\n",
    "train_data = np.loadtxt(\"downloaded.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asfarray(train_data[:1200, 1:])\n",
    "y_train = np.asfarray(train_data[:1200, 0])\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Visualization\n",
    "\n",
    "We can use the help function 'display_digit' to display the image of each data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first training sample\n",
    "display_digit(x_train[0,:], y_train[0], \"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 K-means Clustering\n",
    "\n",
    "In this section we will learn how to implement the k-means algorithm. The procedure is quite simple:\n",
    "\n",
    "1. Initialize the cluster centers (randomly in our case, but there are more clever methods for initialization out there!)\n",
    "2. Loop until the cluster centers don't move anymore or we reach the max number of iterations:\n",
    "    1. Find the distance of each point to the cluster centers.\n",
    "    2. Assign each data point to the closest cluster center.\n",
    "    3. Update the cluster centers as the mean of the data points assigned to that cluster.\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will initialize K cluster centers randomly. Pick K values randomly from the given dataset as initial cluster centers and return them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_centers(data, K):\n",
    "    \"\"\"\n",
    "    Randomly pick K data from the input data as starting points for centers.\n",
    "    \n",
    "    input: \n",
    "        data: ndarray of shape (N, d) where N is the number of pixels, d is number of features.\n",
    "        K: int, the number of clusters.\n",
    "    output:\n",
    "        center: ndarray of shape (K, d). Initial cluster centers.\n",
    "    \n",
    "    \"\"\"    \n",
    "    np.random.seed(0)\n",
    "    random_idx = np.random.permutation(data.shape[0])\n",
    "    # select the first K random index and use these index to select centers from data\n",
    "    center = data[random_idx[:K]]\n",
    "       \n",
    "    return center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to first initialize 10 cluster centers and then visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test code for init_centers, define the number of clusters (for example, 10)\n",
    "# and dispaly the initial centers\n",
    "original_centers = init_centers(x_train,10)\n",
    "for center in original_centers:\n",
    "    display_vector(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us implement some essential components of the k-means algorithm: a function to compute the distance of each data point to the cluster centers and a function to assign each data point to the closest cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def compute_distance(data, centers, K):\n",
    "    \"\"\"\n",
    "    Compute the euclidean distance between each datapoint and each center.\n",
    "    \n",
    "    input:    \n",
    "        data: ndarray of shape (N, d) where N is the number of data points, d is the number of features (:=pixels).\n",
    "        centers: ndarray of shape (K, d). Centers of K clusters.\n",
    "        K: number of clusters.\n",
    "        \n",
    "    output:\n",
    "        distance: ndarray of shape (N, K).\n",
    "    \"\"\"\n",
    "    distance = np.zeros((data.shape[0], K))\n",
    "    for k in range(K):\n",
    "        # compute the euclidean distance for each data to each center\n",
    "        center_k = centers[k, :]\n",
    "        l2distance_k = np.sqrt(((data - center_k)**2).sum(axis=1))\n",
    "        distance[:, k] = l2distance_k\n",
    "        \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_cluster(distance):\n",
    "    \"\"\"\n",
    "    Assign datapoints to clusters according to minimum input distance.\n",
    "    \n",
    "    input:\n",
    "        distance: ndarray of shape (N, K). the distance of each data point to each cluster center.\n",
    "\n",
    "    output:\n",
    "        cluster_assignments: ndarray of shape (N,) cluster assignment of each datapoint.\n",
    "    \"\"\"\n",
    "    cluster_assignments = np.argmin(distance, axis=1)\n",
    "    return cluster_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the results after building clusters based on the initial cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = compute_distance(x_train, original_centers, 10)\n",
    "cluster_assignments = find_closest_cluster(distance)\n",
    "\n",
    "# the number of clusters should be the same as the number of centers, which is 10 here\n",
    "print ('the number of clusters are: ',len(original_centers))\n",
    "for i in np.arange(no_of_different_labels):\n",
    "    print ('the number of data points assigned to the %d cluster is %d'%(i+1,np.sum(cluster_assignments==i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we need to update the cluster centers as the mean of the data points assigned to each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centers(data, cluster_assignments, K):\n",
    "    \"\"\"\n",
    "    compute the center of each cluster\n",
    "\n",
    "    input: \n",
    "        data: input data, shape is (N,d) where N is the number of samples, d is number of features\n",
    "        cluster_assignments: the assigned cluster of each data sample, shape is (N,)\n",
    "        K: the number of clusters\n",
    "\n",
    "    output:\n",
    "        centers: the new centers of each cluster, shape is (K,d) where K is the number of clusters \n",
    "        and d is the number of features \n",
    "    \"\"\"\n",
    "    centers = np.zeros((K, data.shape[1]))\n",
    "    for k in range(K):\n",
    "        centers[k, :] = np.mean(data[cluster_assignments == k], axis=0)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_centers = compute_centers(x_train, cluster_assignments, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means is an iteration of first finding cluster centers, then building new clusters. We iterate between these two steps until we converge. You can say that the algorithm has converged when the cluster centers do not move anymore. Fill in the function below to perform this iteration.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means(data, K, max_iter):\n",
    "    \"\"\"\n",
    "    Main function that combines all the former functions together to build the K-means algorithm.\n",
    "    \n",
    "    Input: \n",
    "        data: ndarray of shape (N, d) where N is the number of pixels, d is number of features.\n",
    "        K: int, the number of clusters.\n",
    "        max_iter: int, the maximum number of iterations\n",
    "    \n",
    "    output:\n",
    "        centers: ndarray of shape (K, d). Final cluster centers.\n",
    "        cluster_assignments: ndarray of shape (N,) index of assigned cluster for each data point.\n",
    "    \"\"\"\n",
    "    centers = init_centers(data, K)\n",
    "    for i in range(max_iter):\n",
    "        old_centers = centers.copy()\n",
    "        distance = compute_distance(data, old_centers, K)\n",
    "        cluster_assignments = find_closest_cluster(distance)\n",
    "        centers = compute_centers(data, cluster_assignments, K)\n",
    "        # End of the algorithm if the centers have not moved\n",
    "        if np.all(old_centers == centers):\n",
    "            break\n",
    "    return centers, cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_centers, cluster_assignments = k_means(x_train, 10, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data point now has a cluster assignment from \"0,..,9\". However, these numbers do not really reflect the label of the cluster (because they are shuffled). For example an image may belong to the 0th cluster, but this does not mean the image depicts 0. But we have access to the true label of each data point in y_label. Let us now make use of these.\n",
    "\n",
    "If we want to assign the true label to each cluster after k-means, we can do so via voting. We have now assigned to each cluster some data samples. The label of the cluster will be assigned as the most common label among these data samples (the mode). Each data point within the cluster will take the label of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "def assign_labels_to_centers(data, cluster_assignments, true_labels, centers):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        data: ndarray of shape (N, d) where N is the number of samples, d is number of features.\n",
    "        cluster_assignments: ndarray of shape (N,) assigned cluster index for each data point.\n",
    "        true_labels: ndarray of shape (N,), training labels from the dataset\n",
    "        centers: ndarray of shape (N, d). Final cluster centers.\n",
    "        \n",
    "    Returns: \n",
    "        new_labels: ndarray of shape (N,). The labels assigned to each data point after clustering, via k-means.\n",
    "        cluster_center_label: ndarray of shape (K,). The labels of the cluster centers\n",
    "    \"\"\"\n",
    "    new_labels = np.zeros(data.shape[0],)\n",
    "    cluster_center_label = np.zeros(centers.shape[0])\n",
    "    for i in range(len(centers)):\n",
    "        mode_res = mode(true_labels[cluster_assignments==i])[0][0]\n",
    "        cluster_center_label[i] = mode_res\n",
    "        new_labels[cluster_assignments==i] = cluster_center_label[i]\n",
    "    return new_labels, cluster_center_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have assigned labels to our data points, we can check for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(pred_labels, gt_labels):\n",
    "    return 100 * np.mean(pred_labels == gt_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run and test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_centers, cluster_assignments = k_means(x_train, 10, 1000)\n",
    "pred_labels, cluster_center_label = assign_labels_to_centers(x_train, cluster_assignments, y_train, final_centers)\n",
    "print(\"Accuracy is\", accuracy_fn(pred_labels, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the data with their predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(x_train[:10,:]):\n",
    "    display_digit(x, pred_labels[i], \"inferred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, center in enumerate(final_centers):\n",
    "    display_digit(center, cluster_center_label[i], \"inferred\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}